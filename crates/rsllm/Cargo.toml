[package]
name = "rsllm"
version = "0.1.0"
edition = "2021"
authors = ["LEVAL Team"]
license = "MIT"
repository = "https://github.com/levalhq/rrag"
homepage = "https://github.com/levalhq/rrag/tree/main/crates/rsllm"
documentation = "https://docs.rs/rsllm"
description = "Rust-native LLM client library with multi-provider support and streaming capabilities"
keywords = ["llm", "ai", "openai", "claude", "ollama"]
categories = ["api-bindings", "web-programming", "network-programming"]

[features]
default = ["openai", "streaming"]
openai = ["dep:reqwest"]
claude = ["dep:reqwest"]
ollama = ["dep:reqwest"]
streaming = ["dep:tokio-stream", "dep:futures-util"]
json-schema = ["dep:schemars"]

[dependencies]
# Async runtime
tokio = { version = "1.0", features = ["macros", "rt-multi-thread", "time", "net"] }
tokio-stream = { version = "0.1", optional = true }
futures-util = { version = "0.3", optional = true }
async-trait = "0.1"

# HTTP client
reqwest = { version = "0.12", features = ["json", "stream"], optional = true }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
schemars = { version = "0.8", optional = true }

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Utilities
uuid = { version = "1.0", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
url = { version = "2.5", features = ["serde"] }
base64 = "0.22"

# Streaming
pin-project-lite = "0.2"
bytes = "1.0"

# Configuration
config = "0.14"
dotenv = "0.15"

[dev-dependencies]
tokio-test = "0.4"
wiremock = "0.6"

[lib]
name = "rsllm"
path = "src/lib.rs"